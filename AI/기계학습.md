### 기계 학습 용어 정리

- 라벨
  : 예측하는 항목 (단순 선형 회귀의 y 변수)

- 특성
  : 입력 변수(단순 선형 회귀의 x 변수), 실제 기계학습 프로젝트에서는 많은 특성들이 포함된 입력 데이터를 다룸

- 모델
  : 특성(x변수)와 라벨(y변수)간의 관계(함수)을 정의, 데이터와 학습 과정을 통해서 모델을 만듬

- 회귀
  : 연속적인 값(실수형) 예측 -> ex) 2달 뒤 대전 아파트의 평균 가격은?

- 분류
  : 불연속적인 값(정수형) 예측 -> ex) 이 이미지 속 사람은 컴퓨터공학과 학생인가요? 아니오(0), 예(1)

### 데이터셋의 중요성

- 데이터셋 품질

  - 주어진 응용에 맞는 충분히 다양한 데이터를 충분한 양만큼 수집 -> 추정 정확도 높아짐
  - 예) 정면 얼굴만 가진 데이터셋으로 학습하고 나면, 측면 얼굴은 매우 낮은 성능
  - 주어진 응용 환경을 자세히 살핀 다음 그에 맞는 데이터셋 확보는 아주 중요함

- 아주 많은 공개 데이터셋
  - 기계 학습의 초파리로 여겨지는 3가지 데이터셋: Iris, MNIST, ImageNet

### 최적화

- 최적화
  : 어떤 목적함수의 값을 최적화(최대화 또는 최소화)시키는 파라미터(변수) 집합을 갖는 문제

- 최적화가 필요한 경우

  - 높은 차원에 비해 훈련집합의 크기가 작아 참인 확률분포를 구하는 일은 불가능
  - 프로그래밍 관점: 알고리즘을 설계하는 것이 불가능한 매우 복잡한 문제

- 기계학습 원리
  - 적절한 모델을 선택, 목적함수를 정의, 모델의 매개변수 공간을 탐색
  - 목적함수가 최저가 되는 최저점을 찾는 전략 사용 (최적화)
  - 목적함수: objective function, lossfunction, cost function 등으로 표현

### 인공신경망

- 사람의 뉴런

  - 두뇌의 가장 작은 정보처리 다누이
  - 세포체는 간단한 연산, 수상돌기는 신호 수신, 축삭은 처리 결과를 전송
  - 사람은 10^11개 정도의 뉴런을 가지며, 뉴런은 1000개 가량 다른 뉴런과 연결되어 있어 10^14개 정도의 연결

- 신경망에는 아주 다양한 모델이 존재함
  - 전방 신경망과 순환 신경망
  - 얕은 신경망과 깊은 신경망

### 퍼셉트론

- 퍼셉트론은 노드, 가중치, 층과 같은 새로운 개념을 도입하고 학습 알고리즘을 창안함
- 퍼셉트론은 가장 간단한 인공 신경망 구조
- 딥러닝을 포함한 현대 신경망은 퍼셉트론을 병렬과 순차 구조로 결합하여 만듬
- 퍼셉트론은 현대 신경망의 중요한 구성 요소

### 퍼셉트론의 구조

- 입력층과 출력층을 가짐
  - 입력층은 연산을 하지 않으므로 퍼셉트론은 단일 층 구조라고 간주
  - 입력층의 i번째 노드는 특징 백터 x=(x1,x2, ..., xd)^T의 요소 xi를 담당
  - 항상 1이 입력되는 바이어스 노드
  - 출력층은 한 개의 노드
  - i번째 입력층 노드와 출력층을 연결하는 엣지는 가중치 wi를 가짐
