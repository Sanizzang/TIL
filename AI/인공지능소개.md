### 인공지능?

인간의 지능이 가지는 학습, 추리, 적응 논증 따위를 기능을 갖춘 컴퓨터 시스템

### 강한 인공지능 vs 약한 인공지능

- 강한 인공지능
  : 다양한 지능의 복합체(예, 터미네이터에 등장하는 인조인간)

- 약한 인공지능
  : 한가지 지능에 특화된 인공지능(현재 인공지능 제품들, 인공지능 스피커, 언어 번역기, 영상 인식기, 알파고 등)

### 규칙 기반 방법론 VS 기계학습 방법론

- 규칙 기반 방법론

  - 사람이 사용하는 규칙을 수집하여 프로그래밍
  - 예) 필기 숫자 인식 프로그램
    - 숫자 3은 "왼쪽에서 보면 위와 아래에 터진 골이 있고, 오른쪽에서 보면 둥근 원호가 중간에서 만나고"와 같은 규칙을 수집
  - 한계 노출: 규칙을 위반하는 샘플이 꾸준히 발생

- 기계학습 방법론
  - 인공지능 초반에는 규칙 기반이 대세였으나 1990년부터 기게학습으로 주도권이 이동함
  - 충분한 데이터를 수집한 다음 기계학습 모델을 학습하는 방법
    (데이터-주도 패러다임)

### 데이터 사이언스 포지션 별 역할

- 데이터 엔지니어(data engineer)
  - 역할: 빅데이터 처리 시스템 설계/구축 (주로 백엔드 개발 업무)
  - 강점: 하둡, 맵리듀스 등 빅데이터 처리 도구와 개발에 능숙
- 데이터 분석가(data analyst)
  - 역할: 데이터를 분석하여 인사이트 도출, 비즈니스의 문제 해결에 집중(주로 컨설팅 업무)
  - 강점: 통계에 능숙하며 비즈니스 지식 보유
- 데이터 과학자(data scientist)
  - 역할: 빅데이터 분석, 데이터 설계 및 모델링(주로 머신러닝 프로젝트 팀장)
  - 강점: 데이터 엔지니어링 + 데이터 분석 + 머신러닝 능숙

### 머신러닝 프로젝트 전체 과정

큰 그림 -> 데이터 구하기 -> 데이터 탐색 시각화 -> 데이터 준비 -> 모델 선택 훈련 -> 모델 조정 -> 시스템 론칭 모니터링 유지 보수

- 데이터 구하기, 시스템 론칭 모니터링 유지보수 = 데이터 엔지니어

- 데이터 탐색 시각화 = 데이터 분석가

- 데이터 탐색 시각화, 데이터 준비, 모델 선택 훈련, 모델 조정 = 확장된 데이터 분석가 업무 영역(최근 추세)

- 데이터 사이언티스트는 머신러닝 프로젝트 전체 과정을 다 총괄한다

- 큰 그림, 데이터 구하기, 시스템 론칭 모니터링이 전체 프로젝트 업무의 80%이상을 차지한다.(주로 백엔드 개발 업무)

- matplotlib, seaborn, visdom -> 데이터 탐색 시각화

- pandas, Numpy -> 데이터 탐색 시각화, 데이터 준비

- scikit learn, PyTorch, TensorFlow -> 데이터 준비, 모델 선택 훈련, 모델 조정

### 데이터 가져오기

- 작업 환경 만들기
  - 파이썬 설치: 주피터 노트북, 넘파이, 판다스, 맷플롯립, 사이킷런 패키지
  - 머신러닝 코드와 데이터셋을 저장할 작업 디렉터리 생성
- 데이터 다운로드
  - housing.csv
- 데이터 구조 훑어보기
- 테스트 세트 만들기
  - 데이터 스누핑(data snooping) 편향
  - 계층 샘플링, 무작위 샘플링

### 머신러닝 알고리즘을 위한 데이터 준비

- 함수를 만들어 데이터 준비 작업을 자동화
  - 어떤 데이터셋에 대해서도 데이터 변환(=전처리)을 손쉽게 반복
  - 향후 프로젝트에 사용할 수 있는 변환 라이브러리를 점진적으로 구축
  - 데이터 정제
    - 머신러닝 알고리즘은 누락된 특성을 다루지 못하므로 이를 처리할 수 있는 함수가 필요
    - 해당 구역을 제거 or 전체 특성을 삭제 or 어떤 값으로 채우기(0, 평균, 중간값 등)
  - 텍스트와 카테고리 형 특성 다루기
    - 머신러닝에서 처리할 수 있도록 수치형 벡터로 변환
  - 나만의 변환기(전처리기) 설계

### 모델 선택과 훈련

- 훈련 세트에서 훈련하고 평가하기
  - 선형 회귀 모델 훈련 (linear regression)
  - 결정트리 모델 훈련 (decision tree)
  - 랜덤 포레스트 모델 훈련 (randow forest)
  - 심층신경망 모델 훈련 (DNN, CNN 등)
- 교차 검증을 사용한 평가
  - k-겹 교차 검증 (k-fold cross-validation)

### 모델 세부 튜닝

- 그리드 탐색 (GridSearchCV)
  - 그리드에 해당하는 비교적 적은 수의 조합 탐색
- 랜덤 탐색 (RandomizedSearchCV)
  - 가능한 모든 조합을 시도하는 대신 각 반복마다 하이퍼파라미터에 임의의 수를 대입하여 지정한 횟수만큼 평가
- 앙상블 방법
  - 최상의 모델과 또 다른 최상의 모델 합치기 (like random forest)
- 최적 모델의 특성 분석
  - 추가 특성을 포함, 불필요한 특성을 제거, 이상치 제외 등
- 테스트 세트로 모델 평가하기

### Numpy

- 파이썬의 수치 계산을 위한 패키지로 import하여 사용 가능
- Numerical Python의 줄임말
- 파이썬 기본 자료구조보다 실행 속도 빠름
  - C 언어를 사용하여 NumPy 핵심모듈을 잘 최적화했기 때문
- 다른 데이터 사이언스 용 파이썬 패키지와 연계성 높음
  - Scipy, Pandas, Matplotlib, Scikit-learn 등의 패키지와 함께 쓰임
- ndarray: fixed-size homogeneous multidimensional array
  - 고정된 크기의 동형 다차원 배열
  - 고정된 크기: 배열 생성할 때 크기 결정
  - 동형: 같은 type의 원소로 구성된 배열
  - list, tuple을 이용하여 생성 가능

```python
import numpy as np
x = np.array((0.1, 0.2, 0.3)) # np.array([0.1, 0.2, 0.3])도 가능
```

### 판다스(Pandas)

- 파이썬의 데이터 처리를 위한 패키지로 import 하여 사용 가능
- 데이터 분석 필수 라이브러리
- 판다스 주요 데이터구조
  - 시리즈(Series)
  - 데이터프레임(DataFrame)

#### 시리즈(Series)

- 1차원 배열 자료구조
  - List, Dictionary, NumPy 자료형도 담을 수 있음
- 색인(index)이라고 하는 배열의 데이터와 연관된 이름 가짐
  - index 1개가 데이터 샘플 1개
- Series 객체 생성: 배열 데이터 이용

```python
obj = pd.Series([4,7,-5,3])
obj
```

- 시리즈 배열(valus) 객체 출력

```python
print(obj.values)

# > [4 7 -5 3]
```

- 시리즈 색인(index) 객체 출력

```python
print(obj.index)

# > RangeIndex(start=0, stop=4, step=1)
```

- index로 임의의 라벨을 사용할 수 있음
  - Numpy와의 차이점
- 파이썬의 사전형(dictionary)와 비슷함
- 사전형을 대체하여 사용 가능

#### 데이터프레임(DataFrame)

- 2차원 배열 자료구조
  - 다차원 배열 구조도 사용 가능, 하지만 주로 2차원 배열 사용
- 데이터프레임 생성 방법
  - 같은 길이의 리스트에 담긴 사전 이용
  - NumPy 배열 이용
- Index(row) 1개가 데이터 샘플 1개 나타냄
- Column 1개는 데이터의 속성 1개 나타냄

### Matplotlib

- 데이터를 차트나 그래프로 시각화하는 패키지
- 데이터 분석 이전에 데이터 이해를 위한 시각화
- 데이터 분석 이후에 결과를 시각화
- 제공하는 차트, 그래프 종류
  - 선 그래프(line plot)
  - 막대 그래프(bar plot)
  - 히스토그램(histogram)
  - 산점도(scatter)
